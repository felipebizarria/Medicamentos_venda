{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avaliação de Desempenho em Modelos de Machine Learning\n",
        "\n",
        "Este notebook traz um panorama sobre **avaliação de desempenho** em modelos de *Machine Learning*, cobrindo:\n",
        "\n",
        "1. **Modelos de classificação**: principais métricas (acurácia, precisão, revocação, F1-score), como interpretar e para que cenários são mais apropriadas.\n",
        "2. **Modelos de regressão**: principais métricas (MSE, RMSE, MAPE), como interpretar e para que cenários são mais apropriadas.\n",
        "3. **Modelos não supervisionados** (ex.: clustering): métricas como Silhouette Score.\n",
        "4. **Validação cruzada** (Cross-Validation): técnica de particionamento dos dados em múltiplos subconjuntos para medir a capacidade de generalização dos modelos.\n",
        "\n",
        "---\n",
        "## 1. O que é Avaliação de Desempenho?\n",
        "\n",
        "Após o treinamento de um modelo de machine learning, precisamos avaliar quão bem ele consegue **generalizar** para dados nunca vistos. Para isso, utilizamos:\n",
        "\n",
        "- **Um conjunto de teste**: dados não usados durante o treinamento.\n",
        "- **Métricas apropriadas**: valores quantitativos que representam o desempenho do modelo.\n",
        "\n",
        "Se o modelo é supervisionado (tem uma variável alvo conhecida), dividimos em **classificação** ou **regressão**:\n",
        "- **Classificação**: prever classes (ex.: spam ou não spam). \n",
        "- **Regressão**: prever valores contínuos (ex.: preço de imóveis).\n",
        "\n",
        "Se o modelo é não supervisionado, por exemplo de **clustering** (agrupamento), precisamos de outras métricas que avaliem a coesão e separação dos clusters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preparação: Bibliotecas e Conjuntos de Dados\n",
        "\n",
        "Vamos começar importando as bibliotecas necessárias e criando (ou carregando) conjuntos de dados para exemplificarmos as métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (2.2.2)\n",
            "Requirement already satisfied: pandas in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (4.55.6)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from scikit-learn) (1.15.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/yuribraz/Code/science_python/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Bibliotecas importadas!\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy pandas matplotlib seaborn scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import make_classification, make_regression, make_blobs\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    mean_squared_error, mean_absolute_percentage_error,\n",
        "    silhouette_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Bibliotecas importadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1. Conjunto de dados para Classificação\n",
        "\n",
        "Vamos criar um dataset sintético de classificação binária (classes 0 e 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formato dados de Classificação - Treino: (700, 2)\n",
            "Formato dados de Classificação - Teste : (300, 2)\n"
          ]
        }
      ],
      "source": [
        "# Criando dados de classificação binária com 2 features\n",
        "X_class, y_class = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=2,\n",
        "    n_informative=2,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Separando em treino e teste\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
        "    X_class, y_class,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Formato dados de Classificação - Treino:\", X_train_cls.shape)\n",
        "print(\"Formato dados de Classificação - Teste :\", X_test_cls.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Conjunto de dados para Regressão\n",
        "\n",
        "Vamos criar um dataset sintético de regressão, onde nossa **variável alvo (y)** é contínua."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formato dados de Regressão - Treino: (700, 1)\n",
            "Formato dados de Regressão - Teste : (300, 1)\n"
          ]
        }
      ],
      "source": [
        "# Criando dados de regressão com 1 feature\n",
        "X_reg, y_reg = make_regression(\n",
        "    n_samples=1000,\n",
        "    n_features=1,\n",
        "    noise=20,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "y_reg = y_reg + 100  # Adiciona um deslocamento para evitar valores próximos de zero\n",
        "\n",
        "# Separando em treino e teste\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Formato dados de Regressão - Treino:\", X_train_reg.shape)\n",
        "print(\"Formato dados de Regressão - Teste :\", X_test_reg.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Conjunto de dados para Clustering (Não Supervisionado)\n",
        "\n",
        "Como exemplo de modelo não supervisionado, usaremos um dataset de *blobs* (grupos) gerado com `make_blobs`, para avaliarmos com **Silhouette Score**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formato dados de Clustering: (300, 2)\n"
          ]
        }
      ],
      "source": [
        "# Criando dados de clustering com 3 centros\n",
        "X_clust, _ = make_blobs(\n",
        "    n_samples=300,\n",
        "    n_features=2,\n",
        "    centers=3,\n",
        "    cluster_std=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Formato dados de Clustering:\", X_clust.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Modelos Supervisionados - Classificação\n",
        "\n",
        "Um problema de classificação prediz uma **classe** (categorias, rótulos) como saída. Por exemplo: *spam ou não spam*, *positivo ou negativo*, *fraude ou não fraude*.\n",
        "\n",
        "### 3.1 Treinando um modelo de classificação (Ex.: Regressão Logística)\n",
        "\n",
        "Vamos utilizar a **Regressão Logística** apenas como exemplo. A ideia aqui é ilustrar como calcular as principais métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo de classificação treinado!\n"
          ]
        }
      ],
      "source": [
        "# Treinando um modelo de classificação\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred_cls = clf.predict(X_test_cls)\n",
        "\n",
        "print(\"Modelo de classificação treinado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Principais Métricas de Classificação\n",
        "\n",
        "**Acurácia**: Proporção de acertos do modelo. Calcula quantas vezes o modelo previu corretamente em relação ao total de previsões.\n",
        "- Sentido: boa métrica quando há *classes balanceadas* e não é crítico diferenciar classes positivas e negativas.\n",
        "\n",
        "**Precisão (Precision)**: Entre as instâncias preditas como positivas, quantas realmente são positivas?\n",
        "- Sentido: útil quando o **custo de um falso positivo** é alto (ex.: diagnóstico médico, detecção de fraude).\n",
        "\n",
        "**Revocação (Recall)**: Entre as instâncias que são de fato positivas, quantas o modelo conseguiu identificar?\n",
        "- Sentido: útil quando o **custo de um falso negativo** é alto (ex.: deixar de detectar um caso positivo).\n",
        "\n",
        "**F1-Score**: Média harmônica entre Precisão e Revocação.\n",
        "- Sentido: equilibrar Precisão e Revocação em um número único, útil quando as classes estão desbalanceadas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Exemplo de Cálculo das Métricas de Classificação\n",
        "Vamos calcular cada métrica a partir das previsões `y_pred_cls`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia : 0.8833\n",
            "Precisão : 0.9275\n",
            "Revocação: 0.8366\n",
            "F1-score : 0.8797\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy_score(y_test_cls, y_pred_cls)\n",
        "prec = precision_score(y_test_cls, y_pred_cls)\n",
        "rec = recall_score(y_test_cls, y_pred_cls)\n",
        "f1 = f1_score(y_test_cls, y_pred_cls)\n",
        "\n",
        "print(f\"Acurácia : {acc:.4f}\")\n",
        "print(f\"Precisão : {prec:.4f}\")\n",
        "print(f\"Revocação: {rec:.4f}\")\n",
        "print(f\"F1-score : {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Modelos Supervisionados - Regressão\n",
        "\n",
        "Um problema de regressão prevê **valores contínuos** como saída. Por exemplo, *preço de imóveis, temperatura, vendas*, etc.\n",
        "\n",
        "### 4.1 Treinando um modelo de Regressão (Ex.: Regressão Linear)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo de regressão treinado!\n"
          ]
        }
      ],
      "source": [
        "# Treinando um modelo de Regressão Linear\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Previsões no conjunto de teste\n",
        "y_pred_reg = reg.predict(X_test_reg)\n",
        "\n",
        "print(\"Modelo de regressão treinado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Principais Métricas de Regressão\n",
        "\n",
        "**MSE (Mean Squared Error)**: Erro médio quadrático. Faz a média dos quadrados dos erros (diferença entre valor real e valor previsto).\n",
        "- Sentido: penaliza erros grandes de forma mais forte (por serem quadrados).\n",
        "\n",
        "**RMSE (Root Mean Squared Error)**: Raiz quadrada do MSE. Traz o erro de volta à mesma escala da variável alvo.\n",
        "- Cálculo manual: \\( RMSE = \\sqrt{MSE} \\)\n",
        "\n",
        "**MAPE (Mean Absolute Percentage Error)**: Erro percentual médio absoluto. Mede o erro em porcentagem em relação aos valores reais.\n",
        "- Sentido: útil para interpretar o erro como % dos valores reais.\n",
        "- Cuidado: pode não ser confiável quando há valores reais próximos de zero.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Exemplo de Cálculo das Métricas de Regressão\n",
        "- Veremos o cálculo manual para MSE e RMSE, e o uso de funções do `scikit-learn`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Cálculo Manual ---\n",
            "MSE  (manual): 417.5302\n",
            "RMSE (manual): 20.4336\n",
            "\n",
            "--- scikit-learn ---\n",
            "MSE  (sklearn): 417.5302\n",
            "RMSE (sklearn): 20.4336\n",
            "MAPE (sklearn): 18.72%\n"
          ]
        }
      ],
      "source": [
        "# Cálculo manual MSE e RMSE\n",
        "errors = y_test_reg - y_pred_reg\n",
        "mse_manual = np.mean(errors**2)\n",
        "rmse_manual = np.sqrt(mse_manual)\n",
        "\n",
        "# Usando scikit-learn\n",
        "mse_sklearn = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "\n",
        "# MAPE (scikit-learn >= 1.0), se versão antiga, precisa fazer manual.\n",
        "mape_value = mean_absolute_percentage_error(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(\"--- Cálculo Manual ---\")\n",
        "print(f\"MSE  (manual): {mse_manual:.4f}\")\n",
        "print(f\"RMSE (manual): {rmse_manual:.4f}\")\n",
        "\n",
        "print(\"\\n--- scikit-learn ---\")\n",
        "print(f\"MSE  (sklearn): {mse_sklearn:.4f}\")\n",
        "print(f\"RMSE (sklearn): {rmse_sklearn:.4f}\")\n",
        "print(f\"MAPE (sklearn): {mape_value*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importante\n",
        "O cálculo do MAPE pode ser problemático em datasets com valores reais (`y`) muito próximos de zero. Isso ocorre porque o erro relativo será inflacionado, resultando em um MAPE elevado e não representativo.\n",
        "\n",
        "Para evitar isso:\n",
        "1. Garanta que os valores reais estejam suficientemente distantes de zero.\n",
        "2. Use métricas alternativas, como **SMAPE** ou **MAE**, em casos onde os valores de `y` possam ser muito pequenos.\n",
        "3. No exemplo a seguir, deslocamos os valores de `y` para evitar problemas no cálculo do MAPE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Modelos Não Supervisionados - Clustering\n",
        "\n",
        "Em problemas não supervisionados de *clustering*, não existe uma variável alvo conhecida. Ainda assim, podemos usar métricas que avaliam a coesão e separação dos grupos formados.\n",
        "\n",
        "**Silhouette Score**: varia em geral de -1 a 1. \n",
        "- Valores próximos de 1 indicam que os pontos estão **bem separados** de outros clusters e **próximos** dos pontos do próprio cluster.\n",
        "- Valores próximos de 0 indicam sobreposição ou fronteiras difusas entre clusters.\n",
        "- Valores negativos indicam que os pontos podem estar em clusters \"errados\" (mais próximos de outro cluster do que do seu próprio).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Score: 0.8480\n"
          ]
        }
      ],
      "source": [
        "# Aplicando KMeans em dados de clustering sintéticos\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "labels = kmeans.fit_predict(X_clust)\n",
        "\n",
        "# Calculando o Silhouette Score\n",
        "score = silhouette_score(X_clust, labels)\n",
        "print(f\"Silhouette Score: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como estamos usando `make_blobs` com 3 centros, esperamos encontrar um *Silhouette Score* razoavelmente alto. Em problemas reais, essa métrica pode ajudar a escolher o número de clusters ou comparar diferentes algoritmos de clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Validação Cruzada (Cross-Validation)\n",
        "\n",
        "A **Validação Cruzada** é uma técnica que divide o conjunto de dados em vários blocos (\"folds\"). Em cada iteração, um fold diferente é usado como conjunto de teste, enquanto os demais folds servem para o treinamento.\n",
        "\n",
        "### Vantagens:\n",
        "- Avaliação mais **robusta**, pois usamos diferentes partições para treino e teste.\n",
        "- **Reduz a variância** das estimativas de desempenho.\n",
        "\n",
        "Vamos demonstrar a validação cruzada para um modelo de classificação usando **acurácia** como métrica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scores em cada fold: [0.875 0.91  0.89  0.925 0.915]\n",
            "Acurácia média   : 0.9030\n",
            "Desvio padrão     : 0.0181\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de Cross-Validation em Classificação\n",
        "scores = cross_val_score(\n",
        "    LogisticRegression(),\n",
        "    X_class,\n",
        "    y_class,\n",
        "    cv=5,               # 5 folds\n",
        "    scoring='accuracy'  # Métrica: acurácia\n",
        ")\n",
        "\n",
        "print(f\"Scores em cada fold: {scores}\")\n",
        "print(f\"Acurácia média   : {scores.mean():.4f}\")\n",
        "print(f\"Desvio padrão     : {scores.std():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Com isso, obtemos o desempenho do modelo em 5 partições diferentes. A **média** indica a performance geral, enquanto o **desvio padrão** mostra a variação de desempenho.\n",
        "\n",
        "## Conclusão\n",
        "\n",
        "1. **Classificação**: acurácia, precisão, revocação e F1-score são fundamentais para compreender o desempenho em cenários diferentes (classes balanceadas, custo de erros).\n",
        "2. **Regressão**: MSE, RMSE e MAPE são métricas clássicas para entender o quão distantes as previsões estão dos valores reais.\n",
        "3. **Não supervisionado**: métricas como *Silhouette Score* são úteis para mensurar a qualidade dos clusters.\n",
        "4. **Validação cruzada**: técnica essencial para ter uma visão mais confiável do poder de generalização do modelo."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
